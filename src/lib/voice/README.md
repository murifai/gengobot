# Voice Processing Foundation - Phase 2.2

Comprehensive voice processing system for Gengobot Japanese learning application.

## ğŸ¯ Overview

Complete voice interaction pipeline including:

- **Speech-to-Text**: OpenAI Whisper API + Web Speech API fallback
- **Text-to-Speech**: OpenAI TTS with Japanese-optimized voices
- **Audio Recording**: Browser-based recording with voice activity detection
- **Audio Playback**: Custom player with speed control for learning

## ğŸ“ Architecture

```
src/lib/voice/
â”œâ”€â”€ whisper-service.ts       # Speech-to-Text service
â”œâ”€â”€ tts-service.ts            # Text-to-Speech service
â”œâ”€â”€ web-speech-api.ts         # Browser API fallback
â”œâ”€â”€ audio-processor.ts        # Recording & processing utilities
â””â”€â”€ index.ts                  # Unified exports

src/components/voice/
â”œâ”€â”€ VoiceRecorder.tsx         # Recording component
â””â”€â”€ AudioPlayer.tsx           # Playback component

src/app/api/voice/
â”œâ”€â”€ transcribe/route.ts       # Whisper API endpoint
â””â”€â”€ synthesize/route.ts       # TTS API endpoint

__tests__/voice/
â”œâ”€â”€ whisper-service.test.ts   # Whisper service tests
â”œâ”€â”€ tts-service.test.ts       # TTS service tests
â”œâ”€â”€ components.test.tsx       # Component tests
â””â”€â”€ api-routes.test.ts        # API route tests
```

## ğŸš€ Quick Start

### 1. Basic Speech-to-Text

```typescript
import { whisperService } from '@/lib/voice';

// Transcribe audio file
const result = await whisperService.transcribe(audioFile, {
  language: 'ja',
  responseFormat: 'verbose_json',
});

console.log(result.text); // Transcribed text
console.log(result.duration); // Audio duration
```

### 2. Japanese-Optimized Transcription

```typescript
// With context for better accuracy
const result = await whisperService.transcribeJapanese(audioFile, {
  taskScenario: 'Ordering food at a restaurant',
  expectedPhrases: ['ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã›', 'ã”æ³¨æ–‡ã¯'],
  userLevel: 'N5',
});
```

### 3. Text-to-Speech

```typescript
import { ttsService } from '@/lib/voice';

// Standard synthesis
const result = await ttsService.synthesize('ã“ã‚“ã«ã¡ã¯', {
  voice: 'nova',
  speed: 1.0,
  format: 'mp3',
});

// For language learning (adjusts speed by level)
const learningAudio = await ttsService.synthesizeForLearning(
  'ã“ã‚“ã«ã¡ã¯',
  'N5' // Slower for beginners
);

// With character personality
const personalizedAudio = await ttsService.synthesizeWithPersonality('ã“ã‚“ã«ã¡ã¯', {
  gender: 'female',
  tone: 'friendly',
});
```

### 4. Voice Recorder Component

```tsx
import VoiceRecorder from '@/components/voice/VoiceRecorder';

<VoiceRecorder
  maxDuration={60000} // 60 seconds
  autoStopOnSilence={true}
  silenceDuration={2000}
  onRecordingComplete={(blob, duration) => {
    console.log('Recording complete:', duration);
  }}
  onVoiceDetected={isDetected => {
    console.log('Voice activity:', isDetected);
  }}
/>;
```

### 5. Audio Player Component

```tsx
import AudioPlayer from '@/components/voice/AudioPlayer';

<AudioPlayer
  src={audioBlob}
  autoPlay={false}
  playbackRate={0.85} // Slower for learning
  showControls={true}
  onEnded={() => console.log('Playback finished')}
/>;
```

## ğŸ”Œ API Endpoints

### POST /api/voice/transcribe

Transcribe audio to text using Whisper.

**Request:**

```typescript
const formData = new FormData();
formData.append('audio', audioFile);
formData.append('taskScenario', 'Restaurant ordering');
formData.append('expectedPhrases', JSON.stringify(['ã„ã‚‰ã£ã—ã‚ƒã„ã¾ã›']));

const response = await fetch('/api/voice/transcribe', {
  method: 'POST',
  body: formData,
});

const data = await response.json();
// { success: true, transcript: '...', duration: 2.5 }
```

### POST /api/voice/synthesize

Generate speech from text using TTS.

**Request:**

```typescript
const response = await fetch('/api/voice/synthesize', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'ã“ã‚“ã«ã¡ã¯',
    mode: 'learning', // 'standard' | 'learning' | 'personality'
    userLevel: 'N5',
    voice: 'nova',
    speed: 0.85,
  }),
});

const audioBlob = await response.blob();
```

## ğŸ¨ Features

### Whisper Service

- âœ… Japanese-optimized transcription
- âœ… Context-aware accuracy improvements
- âœ… File validation (25MB limit)
- âœ… Multiple response formats
- âœ… Cost estimation

### TTS Service

- âœ… 6 voice options (male/female/neutral)
- âœ… Speed adjustment (0.25-4.0x)
- âœ… Learning mode (auto-adjusts by JLPT level)
- âœ… Personality-based voice selection
- âœ… Multiple audio formats (mp3, opus, aac, flac)
- âœ… Batch synthesis support

### Audio Recording

- âœ… Voice activity detection
- âœ… Auto-stop on silence
- âœ… Real-time volume visualization
- âœ… Pause/resume functionality
- âœ… Max duration limits
- âœ… Browser permission handling

### Audio Playback

- âœ… Custom speed control (0.5-2.0x)
- âœ… Volume control
- âœ… Progress bar with seeking
- âœ… Time display
- âœ… Auto-play support
- âœ… Loop functionality

### Web Speech API Fallback

- âœ… Browser-native speech recognition
- âœ… Browser-native speech synthesis
- âœ… Japanese language support
- âœ… No API costs for fallback

## ğŸ§ª Testing

```bash
# Run all voice tests
npm test -- __tests__/voice

# Run specific test suite
npm test -- whisper-service.test.ts
npm test -- tts-service.test.ts
npm test -- components.test.tsx
npm test -- api-routes.test.ts
```

## ğŸ“Š Browser Compatibility

| Feature                | Chrome | Firefox | Safari | Edge |
| ---------------------- | ------ | ------- | ------ | ---- |
| MediaRecorder          | âœ…     | âœ…      | âœ…     | âœ…   |
| AudioContext           | âœ…     | âœ…      | âœ…     | âœ…   |
| Web Speech Recognition | âœ…     | âŒ      | âŒ     | âœ…   |
| Web Speech Synthesis   | âœ…     | âœ…      | âœ…     | âœ…   |

## ğŸ’° Cost Considerations

### OpenAI Whisper

- **Pricing**: $0.006 per minute
- **Example**: 10 min/day Ã— 30 days = $1.80/month

### OpenAI TTS

- **Pricing**: $15.00 per 1M characters
- **Example**: 1000 chars/day Ã— 30 days = $0.45/month

### Fallback Strategy

Use Web Speech API for non-critical interactions to reduce costs.

## ğŸ” Security

- âœ… File type validation
- âœ… File size limits (25MB)
- âœ… Text length limits (4096 chars)
- âœ… Input sanitization
- âœ… Error handling
- âœ… Permission management

## ğŸ¯ Learning Optimizations

### Speed Adjustments by JLPT Level

- **N5**: 0.85x (slower for beginners)
- **N4**: 0.90x
- **N3**: 0.95x
- **N2**: 1.00x (normal speed)
- **N1**: 1.05x (slightly faster)

### Voice Recommendations

- **Nova**: Clear female voice (recommended for learning)
- **Echo**: Warm male voice
- **Shimmer**: Soft female voice
- **Onyx**: Deep male voice

### Context-Aware Transcription

Provides scenario and expected phrases to improve accuracy for learning contexts.

## ğŸ“š Next Steps

Phase 2.2 is complete! Ready for:

- **Phase 2.3**: Real-time conversation implementation
- **Phase 3.1**: Task-based learning UI
- **Phase 3.2**: Voice-enabled conversation interface

## ğŸ¤ Integration with Existing Systems

### AI Services

```typescript
import { conversationManager } from '@/lib/ai';
import { whisperService, ttsService } from '@/lib/voice';

// Voice conversation flow
const audioBlob = await recordUserVoice();
const transcript = await whisperService.transcribeJapanese(audioBlob);
const response = await conversationManager.processMessage(transcript);
const speech = await ttsService.synthesizeForLearning(response, userLevel);
```

### Database Integration

```typescript
// Store voice interactions in TaskAttempt
await prisma.taskAttempt.update({
  where: { id: attemptId },
  data: {
    conversationHistory: {
      push: {
        role: 'user',
        content: transcript,
        voiceMetadata: { duration, confidence },
      },
    },
  },
});
```

## ğŸ“– Documentation

- [Development Plan](../../../../docs/Gengobot-app-dev-plan.md)
- [Architecture Overview](../../../../docs/ARCHITECTURE.md)
- [API Documentation](../../../../docs/API.md)
